{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAaM4M5wpEbn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OhIqYOOpEbr"
   },
   "source": [
    "# Download the data\n",
    "\n",
    "If `wget` is not installed on your machine, you may want to try `curl URL > file.txt` or the `urllib` package in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syYSv9-5pEbs"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir data_ghcn\n",
    "cd data_ghcn\n",
    "wget https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/ghcnd-stations.txt\n",
    "wget https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/2020.csv.gz\n",
    "gzip -d 2020.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAUfLs-ZpEbu"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQTCzLBvpEbu"
   },
   "outputs": [],
   "source": [
    "def get_vals(line):\n",
    "    ls = line.split(',')\n",
    "    station = ls[0]\n",
    "    time = ls[1]\n",
    "    val = float(ls[3])\n",
    "    return [station, time, val]\n",
    "\n",
    "def get_stations(filename='data_ghcn/ghcnd-stations.txt'):\n",
    "    df = pd.read_csv(filename, '/t', header=None)\n",
    "    df = df[0].str.split(expand=True)[[0, 1, 2, 3]]\n",
    "    df.columns = ['Station', 'Latitude', 'Longitude', 'Elevation']\n",
    "    return df\n",
    "\n",
    "def process_year(year, stations, col='TAVG', basedir='data_ghcn'):\n",
    "    tavg = []\n",
    "    with open(os.path.join(basedir, \"%s.csv\" % year)) as h:\n",
    "        l = h.readline()\n",
    "        while l:\n",
    "            if col in l:\n",
    "                v = get_vals(l)\n",
    "                if v[0] in stations.Station:\n",
    "                    tavg.append(get_vals(l))\n",
    "            l = h.readline()\n",
    "    df_tavg = pd.DataFrame(tavg, columns=['Station', 'Date', col])\n",
    "    df_merged = df_tavg.merge(stations, left_on='Station', right_on='Station', how='left')\n",
    "    df_merged['Date'] = df_merged['Date'].apply(pd.Timestamp)\n",
    "    for c in ['Latitude', 'Longitude', col, 'Elevation']:\n",
    "        df_merged[c] = df_merged[c].astype(float)\n",
    "    return df_merged[['Station', 'Date', col, 'Latitude', 'Longitude', 'Elevation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2s37lj6pEbx"
   },
   "outputs": [],
   "source": [
    "stations = get_stations()\n",
    "df1 = process_year('2020', stations, col='TAVG')\n",
    "stations = stations[stations.Station.isin(df1.Station)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7oSIBlwpEbz"
   },
   "outputs": [],
   "source": [
    "df2 = process_year('2020', stations, col='PRCP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvweb0BIpEb1"
   },
   "outputs": [],
   "source": [
    "df = df1.merge(df2[['Station', 'Date', 'PRCP']], on=['Station', 'Date'])\n",
    "# df.to_csv('data_ghcn/daily_global_weather_2020.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "GHCN_data_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
